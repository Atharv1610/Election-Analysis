{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webScrape(links):\n",
    "  unique_urls = set()\n",
    "  for link in links:\n",
    "    response = requests.get(link)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    buttons = soup.find_all('a')\n",
    "    url = {button['href'] for button in buttons if 'href' in button.attrs}\n",
    "    unique_urls.update(url)\n",
    "\n",
    "    for link in url:\n",
    "        print(link)\n",
    "    print(f\"Total Links: {len(unique_urls)}\")\n",
    "  return unique_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apps.apple.com/in/app/voter-helpline/id1456535004\n",
      "https://results.eci.gov.in/AcResultGenJune2024/index.htm\n",
      "https://results.eci.gov.in/PcResultGenJune2024/index.htm\n",
      "https://play.google.com/store/apps/details?id=com.eci.citizen\n",
      "https://results.eci.gov.in/AcResultGen2ndJune2024/index.htm\n",
      "index.htm\n",
      "https://results.eci.gov.in/AcResultByeJune2024/\n",
      "Total Links: 7\n"
     ]
    }
   ],
   "source": [
    "url = ['https://results.eci.gov.in/']\n",
    "urls = webScrape(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://results.eci.gov.in/AcResultGen2ndJune2024/index.htm', 'https://results.eci.gov.in/AcResultGenJune2024/index.htm', 'https://results.eci.gov.in/PcResultGenJune2024/index.htm']\n"
     ]
    }
   ],
   "source": [
    "filtered_urls = [url for url in urls if url.endswith('/index.htm')]\n",
    "print(filtered_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from https://results.eci.gov.in/AcResultGen2ndJune2024/index.htm\n",
      "Class tables found in https://results.eci.gov.in/AcResultGen2ndJune2024/index.htm:\n",
      "\n",
      "Fetching data from https://results.eci.gov.in/AcResultGenJune2024/index.htm\n",
      "Class tables found in https://results.eci.gov.in/AcResultGenJune2024/index.htm:\n",
      "\n",
      "Fetching data from https://results.eci.gov.in/PcResultGenJune2024/index.htm\n",
      "Class tables found in https://results.eci.gov.in/PcResultGenJune2024/index.htm:\n",
      "\n",
      "https://results.eci.gov.in/PcResultGenJune2024/index.htm\n"
     ]
    }
   ],
   "source": [
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        page_content = response.content\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {url}\")\n",
    "        return None\n",
    "\n",
    "def categorize_tables(soup, url):\n",
    "    class_table = []\n",
    "    non_class_table = []\n",
    "    \n",
    "    tables = soup.find_all('table')\n",
    "    for table in tables:\n",
    "        if 'table' in table.get('class', []):\n",
    "            class_table.append(url) \n",
    "        else:\n",
    "            non_class_table.append(table)\n",
    "    \n",
    "    return class_table, non_class_table\n",
    "\n",
    "def extract_data(tables, category):\n",
    "    print(f\"\\nExtracting data from {category} tables...\")\n",
    "    for table in tables:\n",
    "        print(table) \n",
    "\n",
    "# Traverse each URL\n",
    "for url in filtered_urls:\n",
    "    print(f\"Fetching data from {url}\")\n",
    "    soup = fetch_data(url)\n",
    "    if soup:\n",
    "        class_tables, non_class_tables = categorize_tables(soup, url)\n",
    "        \n",
    "        # Print the URLs of class tables\n",
    "        print(f\"Class tables found in {url}:\")\n",
    "        print()\n",
    "        \n",
    "        for table_url in class_tables:\n",
    "            print(table_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://results.eci.gov.in/PcResultGenJune2024/index.htm']\n"
     ]
    }
   ],
   "source": [
    "print(class_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from https://results.eci.gov.in/PcResultGenJune2024/index.htm\n",
      "Data written to csv_files\\PcResultGenJune2024.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        page_content = response.content\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_data_to_csv(soup, filename):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        tables = soup.find_all('table')\n",
    "        for table in tables:\n",
    "            if table.find('th'): \n",
    "                headers = [th.text.strip() for th in table.find_all('th')]\n",
    "                writer.writerow(headers)\n",
    "\n",
    "                rows = table.find_all('tr')[1:]  \n",
    "                for row in rows:\n",
    "                    columns = row.find_all('td')\n",
    "                    row_data = [column.text.strip() for column in columns]\n",
    "                    writer.writerow(row_data)\n",
    "\n",
    "output_folder = 'csv_files'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for url in class_tables:\n",
    "    print(f\"Fetching data from {url}\")\n",
    "    soup = fetch_data(url)\n",
    "    if soup:\n",
    "        filename = os.path.join(output_folder, f\"{url.split('/')[-2]}.csv\")  \n",
    "        extract_data_to_csv(soup, filename)\n",
    "        print(f\"Data written to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://results.eci.gov.in/PcResultGenJune2024/index.htm'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "dropdown = soup.find('select', id='ctl00_ContentPlaceHolder1_Result1_ddlState')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<select id=\"ctl00_ContentPlaceHolder1_Result1_ddlState\" name=\"state\" onchange=\"return GetResult(this)\"> <option value=\"\"> Select State Wise </option><option value=\"U01\">Andaman &amp; Nicobar Islands</option><option value=\"S01\">Andhra Pradesh</option><option value=\"S02\">Arunachal Pradesh</option><option value=\"S03\">Assam</option><option value=\"S04\">Bihar</option><option value=\"U02\">Chandigarh</option><option value=\"S26\">Chhattisgarh</option><option value=\"U03\">Dadra &amp; Nagar Haveli and Daman &amp; Diu</option><option value=\"S05\">Goa</option><option value=\"S06\">Gujarat</option><option value=\"S07\">Haryana</option><option value=\"S08\">Himachal Pradesh</option><option value=\"U08\">Jammu and Kashmir</option><option value=\"S27\">Jharkhand</option><option value=\"S10\">Karnataka</option><option value=\"S11\">Kerala</option><option value=\"U09\">Ladakh</option><option value=\"U06\">Lakshadweep</option><option value=\"S12\">Madhya Pradesh</option><option value=\"S13\">Maharashtra</option><option value=\"S14\">Manipur</option><option value=\"S15\">Meghalaya</option><option value=\"S16\">Mizoram</option><option value=\"S17\">Nagaland</option><option value=\"U05\">NCT OF Delhi</option><option value=\"S18\">Odisha</option><option value=\"U07\">Puducherry</option><option value=\"S19\">Punjab</option><option value=\"S20\">Rajasthan</option><option value=\"S21\">Sikkim</option><option value=\"S22\">Tamil Nadu</option><option value=\"S29\">Telangana</option><option value=\"S23\">Tripura</option><option value=\"S24\">Uttar Pradesh</option><option value=\"S28\">Uttarakhand</option><option value=\"S25\">West Bengal</option></select>\n"
     ]
    }
   ],
   "source": [
    "print(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U01\n",
      "S01\n",
      "S02\n",
      "S03\n",
      "S04\n",
      "U02\n",
      "S26\n",
      "U03\n",
      "S05\n",
      "S06\n",
      "S07\n",
      "S08\n",
      "U08\n",
      "S27\n",
      "S10\n",
      "S11\n",
      "U09\n",
      "U06\n",
      "S12\n",
      "S13\n",
      "S14\n",
      "S15\n",
      "S16\n",
      "S17\n",
      "U05\n",
      "S18\n",
      "U07\n",
      "S19\n",
      "S20\n",
      "S21\n",
      "S22\n",
      "S29\n",
      "S23\n",
      "S24\n",
      "S28\n",
      "S25\n"
     ]
    }
   ],
   "source": [
    "bt =[]\n",
    "if dropdown:\n",
    "        options = dropdown.find_all('option')\n",
    "        for option in options:\n",
    "            option_value = option.get('value')\n",
    "            if option_value:  # Check if option_value is not None or empty\n",
    "                print(option_value)\n",
    "                bt.append(option_value)\n",
    "else:\n",
    "    print(\"Dropdown not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U01', 'S01', 'S02', 'S03', 'S04', 'U02', 'S26', 'U03', 'S05', 'S06', 'S07', 'S08', 'U08', 'S27', 'S10', 'S11', 'U09', 'U06', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'U05', 'S18', 'U07', 'S19', 'S20', 'S21', 'S22', 'S29', 'S23', 'S24', 'S28', 'S25']\n"
     ]
    }
   ],
   "source": [
    "print(bt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
